{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim.models.keyedvectors import KeyedVectors as wk\n",
    "\n",
    "model = gensim.models.KeyedVectors.load_word2vec_format('GoogleNews-vectors-negative300.bin', binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Short cleanup: grep -v -e \"juice\" -e \"carolina\" -e \"jam\" -e \"vapor\" -e \"drink\" -e \"space\" -e \"phone\" -e \"drink\" relata_concatvectors.csv > cleaned_relata_concat.csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df_relations = pd.read_csv('cleaned_relata_concat.csv', sep='\\t', usecols=[0,1], names=[\"relations\", \"vectors\"]) # we wont use cosine sim score here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import done\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import Conv1D, GlobalMaxPooling1D\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing import sequence\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import time\n",
    "from keras import metrics\n",
    "from keras.utils import np_utils\n",
    "from keras.layers import Dense, Dropout\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "print('import done')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5 8 8 ... 8 1 8]\n",
      "(13074, 10)\n"
     ]
    }
   ],
   "source": [
    "Y_list = list(df_relations[\"relations\"])\n",
    "#set_Y  = list(set(Y_list))\n",
    "\n",
    "le = LabelEncoder()\n",
    "Y_test = le.fit_transform(Y_list)\n",
    "num_classes = len (set(Y_test) ) \n",
    "\n",
    "print ( Y_test )\n",
    "#Y_arr = array(Y_test)\n",
    "Y_arr = np_utils.to_categorical(Y_test, num_classes)\n",
    "print (Y_arr.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]]\n",
      "[5 8 8 ... 8 1 8]\n",
      "{'IsA': 2, 'synonym': 9, 'antonym': 5, 'memberof': 7, 'MadeOf': 3, 'entails': 6, 'random': 8, 'PartOf': 4, 'HasProperty': 1, 'HasA': 0}\n",
      "odict_keys(['HasA', 'HasProperty', 'IsA', 'MadeOf', 'PartOf', 'antonym', 'entails', 'memberof', 'random', 'synonym'])\n"
     ]
    }
   ],
   "source": [
    "import operator\n",
    "import collections\n",
    "\n",
    "print (Y_arr[:10])\n",
    "print(np.argmax(Y_arr,axis=1))\n",
    "\n",
    "le_rel_mapping = dict(zip(le.classes_, le.transform(le.classes_)))\n",
    "print (le_rel_mapping)\n",
    "sorted_x = sorted(le_rel_mapping.items(), key=operator.itemgetter(1))\n",
    "dict_x = collections.OrderedDict(sorted_x)\n",
    "print(dict_x.keys())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13074,)\n"
     ]
    }
   ],
   "source": [
    "print (Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from numpy  import array\n",
    "\n",
    "X_set_raw = list(df_relations[\"vectors\"])\n",
    "X_set = []\n",
    "\n",
    "for vector_string in X_set_raw:\n",
    "    nums_only = vector_string.strip(\"[] \\n\")\n",
    "    array_ints = [x for x in nums_only.split(\" \")]\n",
    "    str_list = list(filter(None, array_ints)) \n",
    "    float_list = [float(i) for i in str_list]\n",
    "    numpy_arr = array(float_list)\n",
    "    #print (numpy_arr)\n",
    "    X_set.append( numpy_arr )\n",
    "\n",
    "X_arr = array(X_set)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13074, 600)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print (X_arr.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.2578125  -0.25195312  0.04418945 ...  0.13867188 -0.01611328\n",
      "  -0.25      ]\n",
      " [ 0.2578125  -0.25195312  0.04418945 ... -0.05200195 -0.00585938\n",
      "  -0.15625   ]\n",
      " [ 0.11376953 -0.09570312  0.08691406 ... -0.08447266  0.08935547\n",
      "  -0.11083984]\n",
      " ...\n",
      " [ 0.05566406  0.12695312  0.16308594 ...  0.05737305 -0.01434326\n",
      "   0.10986328]\n",
      " [ 0.05566406  0.12695312  0.16308594 ...  0.09521484  0.0546875\n",
      "   0.12060547]\n",
      " [ 0.05566406  0.12695312  0.16308594 ...  0.19433594  0.16796875\n",
      "  -0.04956055]] [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 1. 0.]\n",
      " [0. 0. 0. ... 0. 1. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 1. 0.]\n",
      " [0. 0. 0. ... 0. 1. 0.]\n",
      " [0. 0. 0. ... 0. 1. 0.]]\n"
     ]
    }
   ],
   "source": [
    "train_num = 1000\n",
    "x_test = X_arr[:train_num]\n",
    "y_test = Y_arr[:train_num]\n",
    "y_test_nums = Y_test[:train_num]\n",
    "x_train = X_arr[train_num:]\n",
    "y_train = Y_arr[train_num:]\n",
    "\n",
    "print (x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compile done\n",
      "Train on 12074 samples, validate on 1000 samples\n",
      "Epoch 1/5\n",
      "12074/12074 [==============================] - 4s 340us/step - loss: 1.3170 - acc: 0.5618 - categorical_accuracy: 0.5618 - val_loss: 1.0738 - val_acc: 0.6280 - val_categorical_accuracy: 0.6280\n",
      "Epoch 2/5\n",
      "12074/12074 [==============================] - 3s 280us/step - loss: 0.9860 - acc: 0.6522 - categorical_accuracy: 0.6522 - val_loss: 0.9843 - val_acc: 0.6540 - val_categorical_accuracy: 0.6540\n",
      "Epoch 3/5\n",
      "12074/12074 [==============================] - 4s 299us/step - loss: 0.7638 - acc: 0.7300 - categorical_accuracy: 0.7300 - val_loss: 0.9564 - val_acc: 0.6920 - val_categorical_accuracy: 0.6920\n",
      "Epoch 4/5\n",
      "12074/12074 [==============================] - 3s 280us/step - loss: 0.5632 - acc: 0.8023 - categorical_accuracy: 0.8023 - val_loss: 1.0139 - val_acc: 0.6860 - val_categorical_accuracy: 0.6860\n",
      "Epoch 5/5\n",
      "12074/12074 [==============================] - 3s 269us/step - loss: 0.4059 - acc: 0.8558 - categorical_accuracy: 0.8558 - val_loss: 1.0763 - val_acc: 0.6860 - val_categorical_accuracy: 0.6860\n"
     ]
    }
   ],
   "source": [
    "def get_simple_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(520, activation='relu', input_dim=600 ))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(250, activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['acc',metrics.categorical_accuracy])\n",
    "    print('compile done')\n",
    "    return model\n",
    "\n",
    "  \n",
    "def check_model(model,x_train,y_train, x_val,y_val):\n",
    "    model.fit(x_train,y_train,batch_size=32,epochs=5,verbose=1,validation_data=(x_val, y_val))\n",
    "    \n",
    "m = get_simple_model()\n",
    "check_model(m,x_train, y_train, x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5 8 8 ... 8 1 8]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "       HasA       0.65      0.58      0.61        53\n",
      "HasProperty       0.70      0.81      0.75        85\n",
      "        IsA       0.59      0.52      0.55       141\n",
      "     MadeOf       0.47      0.53      0.50        17\n",
      "     PartOf       0.52      0.58      0.55        43\n",
      "    antonym       0.57      0.44      0.50        89\n",
      "    entails       0.00      0.00      0.00         3\n",
      "   memberof       0.78      0.85      0.81       501\n",
      "     random       0.29      0.22      0.25        68\n",
      "\n",
      "avg / total       0.67      0.69      0.68      1000\n",
      "\n",
      "[4 8 9 8 9 9 1 8 8 9 8 8 8 8 8 9 2 8 8 8 1 8 8 1 0 2 8 8 8 8 0 8 8 8 4 9 8\n",
      " 8 0 0 0 1 1 0 8 2 8 1 8 8 0 8 0 8 8 0 1 8 8 8 2 8 1 8 8 8 8 8 1 8 8 2 8 8\n",
      " 4 2 8 5 5 2 8 9 8 8 1 8 8 9 8 1 9 8 2 4 1 2 8 8 8 2 2 2 2 8 8 8 8 2 2 8 8\n",
      " 8 8 8 8 1 2 8 3 8 4 1 8 8 2 8 8 8 5 8 8 8 2 5 5 5 5 8 8 8 1 8 1 0 8 0 0 0\n",
      " 8 8 8 0 0 8 8 1 0 8 8 8 5 8 8 4 8 3 8 8 8 0 4 8 2 0 2 8 1 8 8 8 8 8 8 8 8\n",
      " 1 8 5 8 8 8 5 5 8 5 2 5 8 8 8 1 5 8 1 8 1 2 0 8 8 0 1 1 2 4 8 0 8 8 1 8 8\n",
      " 2 8 8 8 8 5 2 2 2 8 2 8 1 8 8 8 8 8 3 8 8 8 8 8 8 1 1 1 0 8 8 8 0 4 0 1 8\n",
      " 8 0 0 1 1 1 8 8 8 4 8 1 8 8 9 8 8 9 8 8 8 4 4 4 8 4 8 8 8 8 8 4 9 8 8 8 8\n",
      " 4 8 8 8 4 4 4 8 5 1 8 8 8 8 5 4 8 8 8 1 8 5 8 2 4 8 8 8 1 8 8 8 8 1 2 8 8\n",
      " 8 8 8 8 4 2 2 8 4 4 8 2 8 8 8 2 2 1 8 2 9 5 8 8 5 5 8 8 4 8 2 2 8 9 5 2 8\n",
      " 8 8 1 8 2 8 8 2 8 8 8 2 9 8 8 1 8 3 8 3 8 0 3 8 8 8 8 9 2 8 6 8 5 8 5 9 9\n",
      " 8 8 2 0 2 8 2 8 8 8 4 8 1 1 2 2 8 4 9 8 8 4 8 8 2 3 8 2 8 3 8 5 1 8 8 1 8\n",
      " 8 1 8 5 8 8 8 1 8 4 1 1 5 0 1 8 8 1 8 1 1 8 2 8 5 5 8 1 5 8 2 8 8 1 8 8 1\n",
      " 1 5 8 2 1 8 8 4 8 8 8 9 9 8 8 8 8 8 8 5 8 8 5 5 8 8 5 5 8 5 8 9 8 5 5 8 1\n",
      " 8 3 8 3 3 3 8 9 9 8 8 8 8 8 4 9 8 8 8 1 2 8 8 8 2 8 1 8 4 8 8 3 8 2 8 2 8\n",
      " 8 8 8 1 8 8 8 8 1 8 8 8 3 2 8 8 1 8 0 8 1 8 8 8 3 2 8 8 8 2 1 8 5 2 8 4 8\n",
      " 8 8 8 2 8 8 2 8 8 8 8 8 8 8 8 8 8 1 8 8 5 4 8 8 1 1 9 8 8 8 9 2 8 1 8 8 8\n",
      " 8 2 1 2 8 8 1 8 8 2 8 5 8 4 8 2 8 2 8 3 4 8 1 8 8 8 8 1 2 8 2 8 2 8 8 8 0\n",
      " 8 8 1 8 8 0 8 9 8 8 2 1 4 0 8 0 1 4 8 2 4 9 2 0 9 8 0 9 4 8 8 4 2 2 2 8 8\n",
      " 8 9 8 5 4 8 8 8 8 1 2 1 3 8 1 8 1 4 8 1 8 4 4 8 8 1 8 8 8 8 0 8 0 8 8 8 8\n",
      " 8 2 8 2 2 8 2 2 1 8 8 5 8 5 5 8 8 5 8 2 5 8 1 5 8 4 1 8 8 1 8 8 8 9 1 1 1\n",
      " 0 0 8 8 8 8 8 8 4 1 8 0 8 0 0 9 0 8 0 8 4 0 8 8 8 2 8 8 8 8 0 2 8 2 8 2 8\n",
      " 2 1 8 3 8 8 2 8 5 8 8 1 8 0 8 1 8 3 8 8 5]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1428: UserWarning: labels size, 9, does not match size of target_names, 10\n",
      "  .format(len(labels), len(target_names))\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "from sklearn.metrics import accuracy_score,classification_report\n",
    "\n",
    "predictions = m.predict(x_test)\n",
    "#print (\"Predictions: \", predictions)\n",
    "labels = np.argmax(predictions, axis=-1)\n",
    "#print (le.inverse_transform(labels))\n",
    "print (Y_test)\n",
    "\n",
    "target_names = ['HasA', 'HasProperty', 'IsA', 'MadeOf', 'PartOf', 'antonym', 'entails', 'memberof', 'random', 'synonym']  # 0 begin, 1 end, 2 blank\n",
    "\n",
    "print( classification_report( y_test_nums, labels, target_names = target_names ) )\n",
    "\n",
    "print(labels[-835:])\n",
    "\n",
    "#print(Yvalid[-835:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "bad input shape (12074, 10)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-99-3961d8826ec8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m########\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mclf_logreg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mclf_logreg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"Logistic regression: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclf_logreg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/sklearn/linear_model/logistic.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1214\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1215\u001b[0m         X, y = check_X_y(X, y, accept_sparse='csr', dtype=_dtype,\n\u001b[0;32m-> 1216\u001b[0;31m                          order=\"C\")\n\u001b[0m\u001b[1;32m   1217\u001b[0m         \u001b[0mcheck_classification_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1218\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    576\u001b[0m                         dtype=None)\n\u001b[1;32m    577\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 578\u001b[0;31m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcolumn_or_1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwarn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    579\u001b[0m         \u001b[0m_assert_all_finite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    580\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my_numeric\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'O'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcolumn_or_1d\u001b[0;34m(y, warn)\u001b[0m\n\u001b[1;32m    612\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    613\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 614\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"bad input shape {0}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    615\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    616\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: bad input shape (12074, 10)"
     ]
    }
   ],
   "source": [
    "########\n",
    "clf_logreg = LogisticRegression()\n",
    "clf_logreg.fit(x_train, y_train)\n",
    "print (\"Logistic regression: \", clf_logreg.score(x_test, y_test) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
